{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to transform the tables used for compression into Arduino code. The code also generates the functions used to exploit these tables. The `frequency_table.cpp` and `frequency_table.h` files can be placed directly in the Arduino project directory for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import logging\n",
    "#logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# Linear algebra and data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Get version python/keras/tensorflow/sklearn\n",
    "from platform import python_version\n",
    "import sklearn\n",
    "\n",
    "# Loading bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Joblib\n",
    "import joblib\n",
    "\n",
    "# Others\n",
    "import itertools\n",
    "from scipy import linalg\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Folder manipulation\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Garbage collector\n",
    "import gc\n",
    "\n",
    "# For images augmentations\n",
    "# import cv2\n",
    "\n",
    "# For regex\n",
    "import re\n",
    "\n",
    "# Visualizaton\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Create defaultdict\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUFFMAN_DIR = \"MODELS/HUFFMAN/\"\n",
    "RESULTS_DIR = \"RESULTS/\"\n",
    "MODELS_DIR = \"MODELS/\"\n",
    "MAIN_DIR = \"./DATA/\"\n",
    "\n",
    "PROTO = \"SMTP\"\n",
    "\n",
    "# Set keras types\n",
    "#tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# Context\n",
    "LOOK_BACK_CONTEXT = 2 # On rajoute +1 car on prend le dernier paquet comme paquet à compresser...\n",
    "LOOK_AHEAD_CONTEXT = 1 #TIMESTEPS\n",
    "CONTEXT_SIZE = 2 # Nombre timesteps sur les contexts\n",
    "CONTEXT_OUTPUT_SIZE = 30 # Size of contexte in model layer\n",
    "# De preference < 128 car c'est la taille de la\n",
    "# couche GRU avant\n",
    "\n",
    "# Packet\n",
    "LOOK_BACK_PACKET = 16\n",
    "LOOK_AHEAD_PACKET = 1\n",
    "QUANTITY_PACKET = 15000 # Check if similar to training !\n",
    "NUM_SIN = 8\n",
    "NUM_FEATS = NUM_SIN + 1\n",
    "\n",
    "# Filter equipment\n",
    "NB_EQUIP_MAX = 10 # Set to None if no equipment\n",
    "NB_EQUIP_TRAIN = 5 # Set to None if no equipment\n",
    "MODE_EQUIP = \"train\" #\"train\" # or \"test\" or None for both\n",
    "MODEL_MODE_EQUIP = \"train\"\n",
    "NB_EQUIP_LIMIT = NB_EQUIP_MAX # Limit to check to \n",
    "# see if we select the right number\n",
    "# of equipment\n",
    "\n",
    "# Learning parameters\n",
    "SHUFFLE = False # For test generator\n",
    "ALPHABET_SIZE = 2\n",
    "BATCH_SIZE = 1 # For test generator\n",
    "\n",
    "# Size added to header_length IN BYTES\n",
    "EXTRA_SIZE = 0\n",
    "CUSTOM_SIZE = 100 # Take the lead if extra size is define\n",
    "CHECKSUM = True # True = Keep Checksum\n",
    "\n",
    "# For evaluation parallelisation\n",
    "BATCH_PACKET = 2\n",
    "\n",
    "# For Huffman model only\n",
    "CUT_VALUE = 6\n",
    "KEEP_ERROR = True\n",
    "OPTIMAL = True\n",
    "SELECTIVE = True # if True he most rank bit is used (only one)\n",
    "SOFT_MODE = False # True par default permet de prendre la moyenne si le champs est meconnu !\n",
    "DECIMALS = None #None # Si None pas de rounding !\n",
    "\n",
    "# Generated dataset parameters\n",
    "LEFT_PADDING = True # Padding dataset\n",
    "\n",
    "# Name\n",
    "# min(LOOK_BACK_CONTEXT, CONTEXT_OUTPUT_SIZE) if CONTEXT_OUTPUT_SIZE == 0\n",
    "# else LOOK_BACK_CONTEXT == 1 or 2 or 3 or 4...etc\n",
    "# easy to set LOOK_BACK_CONTEXT == 0\n",
    "FULL_NAME = f\"LOSSLESS_CONTEXT{LOOK_BACK_CONTEXT}_PACKET{LOOK_BACK_PACKET}_SIN{NUM_SIN}_{PROTO}\"\n",
    "\n",
    "if (CHECKSUM):\n",
    "        \n",
    "    if (KEEP_ERROR):\n",
    "\n",
    "        if (CUSTOM_SIZE is not None):\n",
    "            EXT_NAME = f\"_WITH_CHECKSUM_CUSTOM_SIZE{CUSTOM_SIZE}_MODE_EQUIP{MODE_EQUIP}_KEEP_ERROR_{CUT_VALUE}\"\n",
    "        else:\n",
    "            EXT_NAME = f\"_WITH_CHECKSUM_EXTRA_SIZE{EXTRA_SIZE}_MODE_EQUIP{MODE_EQUIP}_KEEP_ERROR_{CUT_VALUE}\"\n",
    "\n",
    "    else:\n",
    "\n",
    "        if (CUSTOM_SIZE is not None):\n",
    "            EXT_NAME = f\"_WITH_CHECKSUM_CUSTOM_SIZE{CUSTOM_SIZE}_MODE_EQUIP{MODE_EQUIP}_{CUT_VALUE}\"\n",
    "        else:\n",
    "            EXT_NAME = f\"_WITH_CHECKSUM_EXTRA_SIZE{EXTRA_SIZE}_MODE_EQUIP{MODE_EQUIP}_{CUT_VALUE}\"\n",
    "\n",
    "else:\n",
    "    \n",
    "    if (KEEP_ERROR):\n",
    "\n",
    "        if (CUSTOM_SIZE is not None):\n",
    "            EXT_NAME = f\"_CUSTOM_SIZE{CUSTOM_SIZE}_MODE_EQUIP{MODE_EQUIP}_KEEP_ERROR_{CUT_VALUE}\"\n",
    "        else:\n",
    "            EXT_NAME = f\"_EXTRA_SIZE{EXTRA_SIZE}_MODE_EQUIP{MODE_EQUIP}_KEEP_ERROR_{CUT_VALUE}\"\n",
    "\n",
    "    else:\n",
    "\n",
    "        if (CUSTOM_SIZE is not None):\n",
    "            EXT_NAME = f\"_CUSTOM_SIZE{CUSTOM_SIZE}_MODE_EQUIP{MODE_EQUIP}_{CUT_VALUE}\"\n",
    "        else:\n",
    "            EXT_NAME = f\"_EXTRA_SIZE{EXTRA_SIZE}_MODE_EQUIP{MODE_EQUIP}_{CUT_VALUE}\"\n",
    "                \n",
    "\n",
    "# If the SELECTIVE mode is activated \n",
    "if (SELECTIVE):\n",
    "    EXT_NAME = EXT_NAME + \"_SELECTIVE\"\n",
    "\n",
    "\n",
    "# If the OPTIMAL mode is activated \n",
    "if (OPTIMAL):\n",
    "    EXT_NAME = EXT_NAME + \"_OPTIMAL\"\n",
    "\n",
    "\n",
    "# If the LEFT_PADDING mode is activated \n",
    "if (LEFT_PADDING):\n",
    "    EXT_NAME = EXT_NAME + \"_LEFT_PADDING\"\n",
    "\n",
    "\n",
    "# Set the Seed for numpy random choice\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_huffman_groupby = pd.read_csv(f\"{HUFFMAN_DIR}df_HUFFMAN_{FULL_NAME}{EXT_NAME}.csv\")\n",
    "arr = np.load(f\"{HUFFMAN_DIR}arr_index_pos_HUFFMAN_{FULL_NAME}{EXT_NAME}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS/HUFFMAN/df_HUFFMAN_LOSSLESS_CONTEXT2_PACKET16_SIN8_SMTP_WITH_CHECKSUM_CUSTOM_SIZE100_MODE_EQUIPtrain_KEEP_ERROR_6_SELECTIVE_OPTIMAL_LEFT_PADDING.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"{HUFFMAN_DIR}df_HUFFMAN_{FULL_NAME}{EXT_NAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE DATAFRAME FORMAT \n",
    "def my_func(x, max_length=8):\n",
    "    value = str(x)\n",
    "    length = len(value)\n",
    "    value_extend = \"0\"*(max_length-length)\n",
    "    value = value_extend + value\n",
    "    return value \n",
    "\n",
    "\n",
    "df_huffman_groupby['key'] = df_huffman_groupby['key'].map(\n",
    "    lambda x : my_func(x, max_length=CUT_VALUE))\n",
    "df_huffman_groupby = df_huffman_groupby.groupby(\n",
    "    ['ctx', 'pos', 'key']).mean()\n",
    "key_range = 2**CUT_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change max position to use\n",
    "# MAX_POS_PERCENT = 0.1 # percentage of max value\n",
    "MAX_POS = 347 #int(MAX_POS_PERCENT*arr.shape[1])\n",
    "\n",
    "# Update array\n",
    "arr = arr[:, :MAX_POS, :]\n",
    "\n",
    "# Update dataframe\n",
    "l0 = df_huffman_groupby.index.get_level_values(0)\n",
    "l1 = df_huffman_groupby.index.get_level_values(1)\n",
    "cond = (l1.isin(np.arange(0, MAX_POS)))\n",
    "df_huffman_groupby = df_huffman_groupby[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 347, 6)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_array_size = arr.shape[0]*MAX_POS*arr.shape[2]\n",
    "freqs_array_size = arr.shape[0]*MAX_POS*key_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66624"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_array_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6246"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_array_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000000</th>\n",
       "      <td>0.826607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000001</th>\n",
       "      <td>0.246520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001000</th>\n",
       "      <td>0.024029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001001</th>\n",
       "      <td>0.951837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101000</th>\n",
       "      <td>0.630193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101001</th>\n",
       "      <td>0.626311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           proba\n",
       "key             \n",
       "000000  0.826607\n",
       "000001  0.246520\n",
       "001000  0.024029\n",
       "001001  0.951837\n",
       "100000  0.002392\n",
       "101000  0.630193\n",
       "101001  0.626311"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_huffman_groupby.loc[1, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 frequency_table.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 750.44it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 864.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 991.00it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 109798.53it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 111550.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 129453.83it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"frequency_table.cpp\", \"w\") as text_file:\n",
    "    text_file.write(\"#include \\\"frequency_table.h\\\"\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"FrequencyTable::FrequencyTable():\\n\")\n",
    "    \n",
    "    text_file.write(\"  positionArray{\\n\")\n",
    "    \n",
    "    \n",
    "    # SET POSITION ARRAY\n",
    "\n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        text_file.write(\"    {\\n\")\n",
    "        for j in range(arr.shape[1]):\n",
    "            text_file.write(\"        {\")\n",
    "            for k in range(arr.shape[2]):\n",
    "                # -1 replace with 0 define the absence of position\n",
    "                # so, -1+1 = 0\n",
    "                text_file.write(f\"{arr[i, j, k]+1}\")\n",
    "                \n",
    "                if (k != (arr.shape[2]-1)):\n",
    "                    text_file.write(\",\")\n",
    "                    \n",
    "            text_file.write(\"},\\n\") \n",
    "        text_file.write(\"      },\\n\")\n",
    "    text_file.write(\"  },\\n\")\n",
    "    \n",
    "    \n",
    "    ctx_shape = df_huffman_groupby \\\n",
    "                .index.get_level_values(0) \\\n",
    "                .value_counts() \\\n",
    "                .shape[0]\n",
    "    pos_shape = df_huffman_groupby \\\n",
    "                    .index.get_level_values(1) \\\n",
    "                    .value_counts() \\\n",
    "                    .shape[0]\n",
    "    key_range = 2**len(df_huffman_groupby.loc[\n",
    "        0, 0].index[0])\n",
    "    counters_context = [0]*ctx_shape\n",
    "    counters_all = np.zeros((ctx_shape, pos_shape))\n",
    "    \n",
    "    \n",
    "    # SET FREQS ARRAY\n",
    "    \n",
    "    # FOR UNDERSTANDING\n",
    "    freqs_array = []\n",
    "    freqs_array_ctx = []\n",
    "    \n",
    "    text_file.write(\"  freqsArray{\\n\")\n",
    "    \n",
    "    for i in range(ctx_shape):\n",
    "    #for i in range(1, 2):\n",
    "        \n",
    "        freqs_array_ctx_tmp = []\n",
    "\n",
    "        for j in tqdm(range(pos_shape)):\n",
    "        #for j in tqdm(range(302, 303)):\n",
    "\n",
    "            text_file.write(\"         \")\n",
    "            \n",
    "            # Check if the pos j exist\n",
    "            try:\n",
    "                size = int(df_huffman_groupby.loc[\n",
    "                            i, j].index.values.size)\n",
    "            except:\n",
    "                size = 0\n",
    "            \n",
    "            init_range = 0\n",
    "            end_range = init_range\n",
    "\n",
    "            for k in range(size):\n",
    "\n",
    "                # Extract key value\n",
    "                key = int(df_huffman_groupby.loc[\n",
    "                    i, j].index.values[k], 2)\n",
    "\n",
    "                proba = df_huffman_groupby.loc[\n",
    "                        i, j].values[k][0]\n",
    "\n",
    "                end_range = key\n",
    "                \n",
    "                # On compte le nombre de proba == 0.5\n",
    "                proba_eq_quantity = end_range - init_range\n",
    "                if (proba_eq_quantity > 1):\n",
    "                    \n",
    "                    # Number can't be above 255 because we are uint8_t\n",
    "                    # From 101 to 255 we have 154 value \n",
    "                    nb_value = int(np.ceil(\n",
    "                        proba_eq_quantity / 154))\n",
    "                    \n",
    "                    proba_eq_values = [\n",
    "                        154 for q in range(nb_value-1)]\n",
    "                    proba_eq_values += [\n",
    "                        proba_eq_quantity-((nb_value-1)*154)]\n",
    "                    \n",
    "                    for proba_eq in proba_eq_values:\n",
    "                        proba_tmp = 0.5\n",
    "                        proba_text = int(np.around(\n",
    "                            proba_tmp,decimals=2, out=None)*100)\n",
    "                        proba_eq_quantity_text = proba_eq+100 \n",
    "                        # 100 = la base, le max que l'on peut avoir en proba\n",
    "                        text_file.write(f\"{proba_eq_quantity_text},\")\n",
    "                        \n",
    "                        freqs_array.append(\n",
    "                            proba_eq_quantity_text)\n",
    "                        freqs_array_ctx_tmp.append(\n",
    "                            proba_eq_quantity_text)\n",
    "                        \n",
    "                    counters_context[i] += nb_value\n",
    "                    counters_all[i, j] += nb_value\n",
    "                    \n",
    "                    if (counters_all[i, j] > key_range): # 256 in case of CUT_VALUE = 8\n",
    "                        print(\"[DEBUG] ERROR : \", i, \" // \", j)\n",
    "                        \n",
    "                # Permet un gain de 1 octets on écrit 50 au lieu de 101\n",
    "                elif ((proba_eq_quantity > 0) and (proba_eq_quantity < 2)): # proba_eq_quantity == 1\n",
    "                    #print(\"[DEBUG] ELIF ! \")\n",
    "                    \n",
    "                    proba_tmp = 0.5\n",
    "                    proba_text = int(np.around(\n",
    "                        proba_tmp, decimals=2, out=None)*100) \n",
    "                    # 100 = la base, le max que l'on peut avoir en proba\n",
    "                    text_file.write(f\"{proba_text},\")\n",
    "                    \n",
    "                    freqs_array.append(proba_text)\n",
    "                    freqs_array_ctx_tmp.append(\n",
    "                            proba_text)\n",
    "                    \n",
    "                    counters_context[i] += 1\n",
    "                    counters_all[i, j] += 1\n",
    "                    \n",
    "                proba_text = int(\n",
    "                    np.around(proba,decimals=2, out=None)*100)\n",
    "                text_file.write(f\"{proba_text},\")\n",
    "                \n",
    "                freqs_array.append(proba_text)\n",
    "                freqs_array_ctx_tmp.append(\n",
    "                            proba_text)\n",
    "                \n",
    "                counters_context[i] += 1\n",
    "                counters_all[i, j] += 1\n",
    "                \n",
    "                # Update init_range\n",
    "                init_range = end_range + 1\n",
    "\n",
    "            text_file.write(\"\\n\")\n",
    "            \n",
    "        text_file.write(\"   \\n\")\n",
    "        \n",
    "        freqs_array_ctx.append(freqs_array_ctx_tmp)\n",
    "        \n",
    "    text_file.write(\"  },\\n\")\n",
    "    \n",
    "    \n",
    "    # SET FREQS COUNT\n",
    "    \n",
    "    \n",
    "    freqs_count_array = []\n",
    "    \n",
    "    # Pas de count car il y a 256 valeurs... donc on stock le MAX\n",
    "    text_file.write(\"  freqsCountArray{\\n\")\n",
    "    \n",
    "    for i in range(ctx_shape):\n",
    "        \n",
    "        text_file.write(\"    {\")\n",
    "        freqs_count_array_tmp = []\n",
    "        \n",
    "        for j in tqdm(range(pos_shape)): #pos_shape)):\n",
    "            \n",
    "            size = int(counters_all[i, j]) \n",
    "\n",
    "            text_file.write(f\"{size},\")\n",
    "            freqs_count_array_tmp.append(size)\n",
    "\n",
    "        text_file.write(\"},\\n\")\n",
    "        freqs_count_array.append(\n",
    "            freqs_count_array_tmp)\n",
    "            \n",
    "    text_file.write(\"  },\\n\")\n",
    "    \n",
    "    \n",
    "    # SET FREQS COUNT CONTEXT ARRAY\n",
    "    \n",
    "    freqs_count_context_array = []\n",
    "\n",
    "    text_file.write(\"  freqsCountContextArray{\\n\")\n",
    "    text_file.write(\"    \")\n",
    "    \n",
    "    # Set first step\n",
    "    counters_context = [0] + counters_context\n",
    "    \n",
    "    for i in range(1, ctx_shape+1):\n",
    "        text_file.write(f\"{sum(counters_context[0:i])},\")\n",
    "        freqs_count_context_array.append(\n",
    "            sum(counters_context[0:i]))\n",
    "        \n",
    "    text_file.write(\"\\n  }\\n\")\n",
    "    \n",
    "    text_file.write(\"{\\n\")\n",
    "    \n",
    "    text_file.write(\"  // Track the quantity\\n\")\n",
    "    text_file.write(f\"  sumCountFreqsArray = 0;\\n\")\n",
    "\n",
    "    text_file.write(\"};\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # getIndexFreqsArray\n",
    "    \n",
    "    \n",
    "    text_file.write(\"int FrequencyTable::getIndexFreqsArray( \\n \\\n",
    "      int contextSize, int position, int key)\\n\")\n",
    "    text_file.write(\"{\\n\")\n",
    "    \n",
    "    text_file.write(\"  // Compute sum until position-1\\n\")\n",
    "    text_file.write(\"  for (int i=0; i<position; i++)\\n\")\n",
    "    text_file.write(\"  {\\n\")\n",
    "    text_file.write(\"    sumCountFreqsArray = sumCountFreqsArray + \\\\\\n \\\n",
    "                         freqsCountArray[contextSize][i];\\n\")\n",
    "    text_file.write(\"  }\\n\\n\")\n",
    "\n",
    "    text_file.write(\"  uint8_t countFreqsArray = freqsCountArray[ \\n \\\n",
    "                       contextSize][position];\\n\")\n",
    "    \n",
    "    text_file.write(\"  int indexFreqsArray = this->getIndexFreqsArray( \\n \\\n",
    "                       countFreqsArray, key);\\n\\n\")\n",
    "\n",
    "    text_file.write(\"  return indexFreqsArray;\\n\")\n",
    "    text_file.write(\"}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # getIndexFreqsArray (SURCHARGE)\n",
    "    \n",
    "    \n",
    "    text_file.write(\"int FrequencyTable::getIndexFreqsArray( \\n \\\n",
    "      int countFreqsArray, int key)\\n\")\n",
    "    text_file.write(\"{\\n\")\n",
    "    \n",
    "    text_file.write(\"  int indexFreqsArray = -1;\\n\")\n",
    "    text_file.write(\"  int count = 0;\\n\")\n",
    "    text_file.write(\"  int countTmp = 0;\\n\")\n",
    "    text_file.write(\"  bool exitLoop = false;\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"  int i = 0;\\n\")\n",
    "    text_file.write(\"  while((i < countFreqsArray) && (!exitLoop))\\n\")\n",
    "    text_file.write(\"  {\\n\")\n",
    "    \n",
    "    text_file.write(\"    // Count number of value\\n\")\n",
    "    text_file.write(\"    countTmp = (int)freqsArray[sumCountFreqsArray+i];\\n\")\n",
    "    text_file.write(\"    // Compteur for equal freq value\\n\")\n",
    "    text_file.write(\"    count = count + max(1, countTmp-100);\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"    // -1 because index start from 0\\n\")\n",
    "    text_file.write(\"    if ((count-1) >= key)\\n\")\n",
    "    text_file.write(\"    {\\n\")\n",
    "    text_file.write(\"      indexFreqsArray = sumCountFreqsArray+i;\\n\")\n",
    "    text_file.write(\"      exitLoop = true;\\n\")\n",
    "    text_file.write(\"    }\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"    i = i + 1;\\n\")\n",
    "    text_file.write(\"  }\\n\")\n",
    "\n",
    "    text_file.write(\"  sumCountFreqsArray = sumCountFreqsArray+countFreqsArray;\\n\")\n",
    "    text_file.write(\"  return indexFreqsArray;\\n\")\n",
    "    text_file.write(\"}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # convertBinToInt\n",
    "    \n",
    "    \n",
    "    text_file.write(\"int FrequencyTable::convertBinToInt( \\n \\\n",
    "                          uint8_t* dataBin, int sizeArrayBin)\\n\")\n",
    "    text_file.write(\"{\\n\")\n",
    "    text_file.write(\"int value = 0;\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"for(int i=0; i<sizeArrayBin; i++)\\n\")\n",
    "    text_file.write(\"  {\\n\")\n",
    "    \n",
    "    text_file.write(\"    if (dataBin[i] == 1) // /!\\ A CHANGER si bool !?\\n\")\n",
    "    text_file.write(\"    {\\n\")\n",
    "    text_file.write(\"    value = value + pow(\\n\")\n",
    "    text_file.write(\"      2, sizeArrayBin-1-i);\\n\")\n",
    "    text_file.write(\"    }\\n\")\n",
    "    \n",
    "    text_file.write(\"  }\\n\")\n",
    "    text_file.write(\"  return value;\\n\")\n",
    "    \n",
    "    text_file.write(\"}\\n\\n\")\n",
    "    \n",
    "    # computeKey\n",
    "    \n",
    "    text_file.write(\"int FrequencyTable::computeKey(uint8_t* dataBin, \\n \\\n",
    "                          int context,\\n \\\n",
    "                          int position)\\n\")\n",
    "    text_file.write(\"{\\n\")\n",
    "    \n",
    "    text_file.write(\"  uint16_t* indexes = positionArray[\\n\")\n",
    "    text_file.write(\"    context][position];\\n\")\n",
    "    text_file.write(\"  uint8_t* keyArray = new uint8_t[KEY_SIZE];\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"  // Extract value of array \\n\")\n",
    "    text_file.write(\"  for(int i=0; i<KEY_SIZE; i++)\\n\")\n",
    "    text_file.write(\"  {\\n\")\n",
    "    text_file.write(\"    // If index equal is -1 then indexes[i] == 0\\n\")\n",
    "    text_file.write(\"    // because indexes[i] == -1 take too much space\\n\")\n",
    "    text_file.write(\"    if(indexes[i] == 0)\\n\")\n",
    "    text_file.write(\"    {\\n\")\n",
    "    text_file.write(\"      keyArray[i] = 0;\\n\")\n",
    "    text_file.write(\"    } else {\\n\")\n",
    "    text_file.write(\"      keyArray[i] = dataBin[indexes[i]-1];\\n\")\n",
    "    text_file.write(\"    }\\n\")\n",
    "    text_file.write(\"  }\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"  // Convert binary array to int\\n\")\n",
    "    text_file.write(\"  int key = this->convertBinToInt(\\n\")\n",
    "    text_file.write(\"    keyArray, 8);\\n\")\n",
    "    text_file.write(\"  delete[] keyArray;\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"  return key;\\n\")    \n",
    "    \n",
    "    text_file.write(\"}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # computeFrequency\n",
    "    \n",
    "    \n",
    "    text_file.write(\"float* FrequencyTable::computeFrequency( \\n \\\n",
    "          int indexFreqsArray)\\n\")\n",
    "    text_file.write(\"{\\n\")\n",
    "    \n",
    "    text_file.write(\"  // Check if position is a compress field (eq > 100)\\n\")\n",
    "    text_file.write(\"  // If number is on the trailling value\\n\")\n",
    "    text_file.write(\"  float freq;\\n\")\n",
    "    text_file.write(\"  if (indexFreqsArray == -1)\\n\")\n",
    "    text_file.write(\"  {\\n\")\n",
    "    text_file.write(\"    freq = 0.5;\\n\")\n",
    "    text_file.write(\"  }\\n\")\n",
    "    text_file.write(\"  else\\n\")\n",
    "    text_file.write(\"  {\\n\")\n",
    "    text_file.write(\"    freq = freqsArray[indexFreqsArray] / 100.;\\n\")\n",
    "    text_file.write(\"  }\\n\\n\")\n",
    "\n",
    "    text_file.write(\"  // If number is on 100 \\n\")\n",
    "    text_file.write(\"  float* freqs = new float[ALPHABET_SIZE];\\n\")\n",
    "    text_file.write(\"  if (freq > 1)\\n\")\n",
    "    text_file.write(\"  {\\n\")\n",
    "    text_file.write(\"    freqs[0] = 0.5;\\n\")\n",
    "    text_file.write(\"  }\\n\")\n",
    "\n",
    "    text_file.write(\"  else\\n\")\n",
    "    text_file.write(\"  {\\n\")\n",
    "    text_file.write(\"    freqs[0] = freq;\\n\")\n",
    "    text_file.write(\"  }\\n\\n\")\n",
    "  \n",
    "    text_file.write(\"  freqs[1] = 1-freqs[0];\\n\")\n",
    "    text_file.write(\"  return freqs;\\n\") \n",
    "    text_file.write(\"}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # nextFrequency\n",
    "    \n",
    "    \n",
    "    text_file.write(\"float* FrequencyTable::nextFrequency(uint8_t* dataBin, \\n \\\n",
    "                           int contextSize, \\n \\\n",
    "                           int position) \\n\")\n",
    "    text_file.write(\"{\\n\")\n",
    "    \n",
    "    text_file.write(\"  // Extract value from position\\n\")\n",
    "    text_file.write(\"  int key = this->computeKey( \\n \\\n",
    "        dataBin, contextSize, position);\\n\\n\")\n",
    "\n",
    "    text_file.write(\"  uint8_t countFreqsArray = freqsCountArray[ \\n \\\n",
    "            contextSize][position];\\n\")\n",
    "    text_file.write(\"  int indexFreqsArray = this->getIndexFreqsArray( \\n \\\n",
    "          countFreqsArray, key);\\n\\n\")\n",
    "\n",
    "    text_file.write(\"  float* freqs = this->computeFrequency( \\n \\\n",
    "                      indexFreqsArray);\\n\")\n",
    "    text_file.write(\"  return freqs;\\n\")\n",
    "    \n",
    "    text_file.write(\"}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    # getFrequency\n",
    "    \n",
    "    text_file.write(\"float* FrequencyTable::getFrequency(uint8_t* dataBin,\\n \\\n",
    "                          int contextSize,\\n \\\n",
    "                          int position)\\n\")\n",
    "    text_file.write(\"{\\n\")\n",
    "    \n",
    "    text_file.write(\"  // Extract value from position\\n\")\n",
    "    text_file.write(f\"  int key = this->computeKey(\\n\")\n",
    "    text_file.write(f\"    dataBin, contextSize, position);\\n\\n\")\n",
    "    \n",
    "    text_file.write(f\"  // Init with pre-calculate context\\n\")\n",
    "    text_file.write(f\"  sumCountFreqsArray = freqsCountContextArray[ \\n \\\n",
    "                           contextSize];\\n\")\n",
    "    text_file.write(f\"  int indexFreqsArray = this->getIndexFreqsArray( \\n \\\n",
    "                           contextSize, position, key);\\n\\n\")\n",
    "    \n",
    "    text_file.write(f\"  float* freqs = this->computeFrequency( \\n \\\n",
    "                       indexFreqsArray);\\n\")\n",
    "    \n",
    "    text_file.write(f\"  return freqs;\\n\")\n",
    "    \n",
    "    text_file.write(\"}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freqs_array_ctx_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484\n",
      "1500\n",
      "1573\n"
     ]
    }
   ],
   "source": [
    "# Each line for each context\n",
    "for i in range(len(freqs_array_ctx)):\n",
    "    print(len(freqs_array_ctx[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4557"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freqs_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_huffman_groupby.shape: (3703, 1)\n",
      "uint8_t freqsArray[4557];\n",
      "uint8_t freqsCountArray[3][100];\n",
      "uint32_t freqsCountContextArray[3];\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_huffman_groupby.shape: {df_huffman_groupby.shape}\")\n",
    "print(f\"uint8_t freqsArray[{int(counters_all.sum())}];\")\n",
    "print(f\"uint8_t freqsCountArray[{arr.shape[0]}][{arr.shape[1]}];\")\n",
    "print(f\"uint32_t freqsCountContextArray[{arr.shape[0]}];\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3703, 1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_huffman_groupby.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8_t freqsArray[4557];\n",
      "uint8_t freqsCountArray[3][100];\n",
      "uint32_t freqsCountContextArray[3];\n"
     ]
    }
   ],
   "source": [
    "print(f\"uint8_t freqsArray[{int(counters_all.sum())}];\")\n",
    "print(f\"uint8_t freqsCountArray[{arr.shape[0]}][{arr.shape[1]}];\")\n",
    "print(f\"uint32_t freqsCountContextArray[{arr.shape[0]}];\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 frequency_table.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"frequency_table.h\", \"w\") as text_file:\n",
    "    text_file.write(\"#ifndef FREQ_TABLE_H\\n\")\n",
    "    text_file.write(\"#define FREQ_TABLE_H\\n\")\n",
    "    text_file.write(\"#include <Arduino.h>\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"#define ALPHABET_SIZE     0x02\\n\")\n",
    "    text_file.write(f\"#define KEY_SIZE          0x0{CUT_VALUE}\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"class FrequencyTable\\n\")\n",
    "    text_file.write(\"{\\n\")\n",
    "    \n",
    "    text_file.write(\"  private:\\n\")\n",
    "    \n",
    "    text_file.write(f\"    uint16_t positionArray[{arr.shape[0]}][{arr.shape[1]}][{arr.shape[2]}];\\n\\n\")\n",
    "    \n",
    "    # +10 is for safety\n",
    "    text_file.write(f\"    uint8_t freqsArray[{int(counters_all.sum()+key_range)}];\\n\")\n",
    "    text_file.write(f\"    uint8_t freqsCountArray[{arr.shape[0]}][{arr.shape[1]}];\\n\")\n",
    "    text_file.write(f\"    uint32_t freqsCountContextArray[{arr.shape[0]}];\\n\\n\")\n",
    "    \n",
    "    text_file.write(f\"    int indexFreqsArray;\\n\")\n",
    "    text_file.write(f\"    int sumCountFreqsArray;\\n\\n\")\n",
    "\n",
    "    \n",
    "    text_file.write(\"    // Methods \\n\")\n",
    "    text_file.write(\"    int convertBinToInt(uint8_t* dataBin, \\n \\\n",
    "                           int sizeArrayBin);\\n\")\n",
    "    text_file.write(\"    int computeKey(uint8_t* dataBin,\\n \\\n",
    "                           int context,\\n \\\n",
    "                           int position);\\n\")\n",
    "    text_file.write(\"    int getIndexFreqsArray(int contextSize,\\n \\\n",
    "                           int position,\\n \\\n",
    "                           int key);\\n\")\n",
    "    text_file.write(\"    int getIndexFreqsArray(int countFreqsArray,\\n \\\n",
    "                           int key);\\n\")\n",
    "    text_file.write(f\"    float* computeFrequency(int nextPosition);\\n\\n\")\n",
    "    \n",
    "    \n",
    "    text_file.write(\"  public:\\n\")\n",
    "    text_file.write(\"    // Constructor\\n\")\n",
    "    text_file.write(\"    FrequencyTable();\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"    // Others\\n\")\n",
    "    text_file.write(\"    float* nextFrequency(uint8_t* dataBin, \\n \\\n",
    "                          int contextSize,\\n \\\n",
    "                          int position);\\n\")\n",
    "    text_file.write(\"    float* getFrequency(uint8_t* dataBin, \\n \\\n",
    "                          int contextSize,\\n \\\n",
    "                          int position);\\n\")\n",
    "    \n",
    "    text_file.write(\"    // Others\\n\")\n",
    "    text_file.write(\"    // \\n\")\n",
    "    \n",
    "    text_file.write(\"};\\n\\n\")\n",
    "    \n",
    "    text_file.write(\"#endif\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
